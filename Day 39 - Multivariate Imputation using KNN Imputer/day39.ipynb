{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputer\n",
    "The K-Nearest Neighbors (KNN) imputer is a method for imputing missing values in a dataset by considering the values of the nearest neighbors. It is implemented in scikit-learn as the `KNNImputer` class. Unlike traditional imputation methods, KNN imputation takes into account the similarity between data points to estimate missing values.\n",
    "\n",
    "Here are key points about the KNN imputer:\n",
    "\n",
    "### KNN Imputer:\n",
    "\n",
    "1. **Nearest Neighbor Approach:**\n",
    "   - KNN imputer estimates missing values based on the values of the k-nearest neighbors of a data point.\n",
    "\n",
    "2. **Distance Metric:**\n",
    "   - The imputer typically uses a distance metric (e.g., Euclidean distance) to measure the similarity between data points.\n",
    "\n",
    "3. **Choice of k:**\n",
    "   - The parameter 'k' specifies the number of neighbors to consider. It is an important hyperparameter that can impact imputation accuracy.\n",
    "\n",
    "4. **Weighted Imputation:**\n",
    "   - In some implementations, the imputation can be weighted, where closer neighbors have a higher influence on the imputed value.\n",
    "\n",
    "### Nan Euclidean Distance:\n",
    "\n",
    "In the context of the KNN imputer, \"NaN Euclidean distance\" refers to the handling of missing values when calculating distances between data points. In standard Euclidean distance, the presence of missing values in any of the dimensions can pose challenges. Some implementations, like the one in scikit-learn, address this issue by adjusting the distance calculation when missing values are present.\n",
    "\n",
    "For example, if two data points have missing values in different dimensions, the contribution of those dimensions to the Euclidean distance is adjusted, considering only the dimensions where both data points have non-missing values.\n",
    "\n",
    "#### Formula for NaN Euclidean Distance\n",
    "\n",
    "$ \\text{dist}(x, y) = \\sqrt{\\text{weight} \\cdot \\sum_{i=1}^{n} \\delta_i \\cdot (x_i - y_i)^2} $\n",
    "\n",
    "where:\n",
    "- $ \\text{dist}(x, y) $ is the distance between points $x$ and $y$,\n",
    "- $ n $ is the total number of coordinates,\n",
    "- $ \\delta_i $ is an indicator function equal to 1 if both $x_i$ and $y_i$ are present, and 0 otherwise,\n",
    "- $ x_i $ and $ y_i $ are the values of the $i$-th coordinate of points $x$ and $y$, respectively, and\n",
    "- $ \\text{weight} = \\frac{\\text{Total no. of coordinates}}{\\text{No. of present coordinates}} $.\n",
    "\n",
    "### Example in Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assume 'X' is your feature matrix with missing values\n",
    "\n",
    "# Create KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)  # You can adjust 'n_neighbors' based on your needs\n",
    "\n",
    "# Perform imputation\n",
    "X_imputed = knn_imputer.fit_transform(X)\n",
    "```\n",
    "\n",
    "In this example, the `KNNImputer` is used with a default setting of 5 neighbors. You can adjust the `n_neighbors` parameter based on the characteristics of your dataset. The imputation is performed by considering the values of the k-nearest neighbors for each missing entry.\n",
    "\n",
    "### Considerations:\n",
    "\n",
    "- **Computational Complexity:**\n",
    "  - KNN imputation can be computationally expensive, especially for large datasets, as it involves calculating distances between data points.\n",
    "\n",
    "- **Choice of Distance Metric:**\n",
    "  - The choice of the distance metric can impact imputation results. Euclidean distance is common, but other metrics like Manhattan distance or Minkowski distance can be used.\n",
    "\n",
    "- **Handling Categorical Variables:**\n",
    "  - KNN imputation is primarily designed for numerical data. For categorical variables, additional preprocessing may be required.\n",
    "\n",
    "- **Optimizing Hyperparameters:**\n",
    "  - Consider cross-validation to optimize hyperparameters, such as the number of neighbors ('n_neighbors').\n",
    "\n",
    "KNN imputation can be a powerful method when the missingness in the dataset has a spatial structure, and the imputed values depend on the values of neighboring data points. However, its performance may vary based on the characteristics of the data and the choice of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.impute import KNNImputer,SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')[['Age','Pclass','Fare','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Pclass     Fare  Survived\n",
       "0  22.0       3   7.2500         0\n",
       "1  38.0       1  71.2833         1\n",
       "2  26.0       3   7.9250         1\n",
       "3  35.0       1  53.1000         1\n",
       "4  35.0       3   8.0500         0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age         19.86532\n",
       "Pclass       0.00000\n",
       "Fare         0.00000\n",
       "Survived     0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.7208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>16.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31.3875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.8458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Pclass     Fare\n",
       "30   40.0       1  27.7208\n",
       "10    4.0       3  16.7000\n",
       "873  47.0       3   9.0000\n",
       "182   9.0       3  31.3875\n",
       "876  20.0       3   9.8458"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNNImputer(n_neighbors=3,weights='distance')\n",
    "\n",
    "X_train_trf = knn.fit_transform(X_train)\n",
    "X_test_trf = knn.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7150837988826816"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_trf,y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_trf)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparision with Simple Imputer --> mean\n",
    "\n",
    "si = SimpleImputer()\n",
    "\n",
    "X_train_trf2 = si.fit_transform(X_train)\n",
    "X_test_trf2 = si.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6927374301675978"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train_trf2,y_train)\n",
    "\n",
    "y_pred2 = lr.predict(X_test_trf2)\n",
    "\n",
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
