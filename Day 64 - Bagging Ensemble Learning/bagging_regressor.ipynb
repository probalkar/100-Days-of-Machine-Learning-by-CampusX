{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Regressor\n",
    "\n",
    "The BaggingRegressor is an ensemble learning method provided by Scikit-learn, which implements the bagging (Bootstrap Aggregating) technique for regression tasks. It combines the predictions of multiple base regressors trained on different subsets of the training data to make a final prediction. Here's a detailed overview of the BaggingRegressor:\n",
    "\n",
    "### Key Features and Parameters:\n",
    "\n",
    "1. **Base Estimator**:\n",
    "   - The base estimator is the regression algorithm used to train each base regressor in the ensemble.\n",
    "   - It can be any regressor from Scikit-learn, such as decision trees, linear regression, support vector regression, etc.\n",
    "\n",
    "2. **n_estimators**:\n",
    "   - The number of base regressors (estimators) to include in the ensemble.\n",
    "   - Increasing the number of estimators typically leads to better performance, but it also increases computational complexity.\n",
    "\n",
    "3. **max_samples**:\n",
    "   - The number or proportion of samples to draw from the training data for each base regressor.\n",
    "   - It controls the size of the bootstrap sample used for training each base regressor.\n",
    "   - By default, it is set to the size of the training dataset.\n",
    "\n",
    "4. **max_features**:\n",
    "   - The number or proportion of features to consider for each base regressor.\n",
    "   - It controls the size of the random subset of features used for training each base regressor.\n",
    "   - If set to 1.0, all features are considered for each base regressor.\n",
    "   - If set to less than 1.0, it specifies the proportion of features to consider.\n",
    "   - If set to 'sqrt', it considers the square root of the total number of features.\n",
    "   - If set to 'log2', it considers the logarithm base 2 of the total number of features.\n",
    "\n",
    "5. **bootstrap**:\n",
    "   - Whether to use bootstrap sampling (with replacement) when creating the training datasets for each base regressor.\n",
    "   - If set to True (default), bootstrap sampling is used.\n",
    "   - If set to False, pasting (sampling without replacement) is used.\n",
    "\n",
    "6. **bootstrap_features**:\n",
    "   - Whether to use bootstrap sampling when selecting features for each base regressor.\n",
    "   - If set to True (default), bootstrap sampling is used.\n",
    "   - If set to False, all features are considered for each base regressor.\n",
    "\n",
    "7. **n_jobs**:\n",
    "   - The number of CPU cores to use for parallelizing the training of base regressors.\n",
    "   - If set to -1 (default), all available CPU cores are used.\n",
    "\n",
    "### How BaggingRegressor Works:\n",
    "\n",
    "1. **Training**:\n",
    "   - The BaggingRegressor first creates multiple bootstrap samples (or subsets) of the training data, each containing a random subset of instances (samples).\n",
    "   - Then, it trains a base regressor (specified by the base estimator parameter) independently on each bootstrap sample.\n",
    "   - Each base regressor learns to predict the target variable based on the features present in its respective bootstrap sample.\n",
    "\n",
    "2. **Prediction Aggregation**:\n",
    "   - During prediction, each base regressor makes its own individual predictions on the unseen data.\n",
    "   - The BaggingRegressor aggregates the predictions of all base regressors by averaging them to obtain the final prediction.\n",
    "\n",
    "### Advantages:\n",
    "\n",
    "- **Variance Reduction**: BaggingRegressor reduces overfitting and variance by combining predictions from multiple base regressors trained on different subsets of the data.\n",
    "  \n",
    "- **Robustness**: By training models on diverse subsets of the data, BaggingRegressor is more robust to outliers and noise.\n",
    "\n",
    "- **Parallelization**: BaggingRegressor supports parallel training of base regressors, allowing for efficient utilization of computational resources.\n",
    "\n",
    "### Example Usage:\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define base regressor\n",
    "base_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# Create BaggingRegressor\n",
    "bagging_regressor = BaggingRegressor(base_estimator=base_regressor, n_estimators=10, max_samples=0.8, max_features=0.8)\n",
    "\n",
    "# Train BaggingRegressor\n",
    "bagging_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagging_regressor.predict(X_test)\n",
    "```\n",
    "\n",
    "In this example, we create a BaggingRegressor with a base decision tree regressor and train it on the training data (X_train, y_train). We then make predictions on the test data (X_test) using the trained BaggingRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gDkpJntIt2i",
    "outputId": "d6de2d68-c5bd-4e89-c9fc-53d1e5911f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset features names : ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "Dataset features size : (506, 13)\n",
      "Dataset target size : (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\r\n",
    "\r\n",
    "boston = datasets.load_boston()\r\n",
    "X_boston, Y_boston = boston.data, boston.target\r\n",
    "print('Dataset features names : '+ str(boston.feature_names))\r\n",
    "print('Dataset features size : '+ str(boston.data.shape))\r\n",
    "print('Dataset target size : '+ str(boston.target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-_V66s1ZJqOj"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "from sklearn.neighbors import KNeighborsRegressor\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.tree import DecisionTreeRegressor\r\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uR-MoTpeI1gw",
    "outputId": "74fbcb52-72e2-4c48-f2c3-55b4d1ab20d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test Sets Sizes :  (404, 13) (102, 13) (404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_boston, Y_boston , train_size=0.80, test_size=0.20, random_state=123)\r\n",
    "print('Train/Test Sets Sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aR1Nk97qLePU"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\r\n",
    "dt = DecisionTreeRegressor()\r\n",
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QVq3vX0LvlS",
    "outputId": "df283b3e-c155-40ec-e77d-ff4759a65aff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,Y_train)\r\n",
    "dt.fit(X_train,Y_train)\r\n",
    "knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yW4a1bHJL2jz"
   },
   "outputs": [],
   "source": [
    "y_pred1 = lr.predict(X_test)\r\n",
    "y_pred2 = dt.predict(X_test)\r\n",
    "y_pred3 = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx7R5oxSMBpa",
    "outputId": "b09b60cc-8869-4fd2-84f1-522cf41e7498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for LR 0.6592466510354125\n",
      "R^2 score for DT 0.4379566831493381\n",
      "R^2 score for KNN 0.5475962186976784\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 score for LR\",r2_score(Y_test,y_pred1))\r\n",
    "print(\"R^2 score for DT\",r2_score(Y_test,y_pred2))\r\n",
    "print(\"R^2 score for KNN\",r2_score(Y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tz7obCmMI_Pa",
    "outputId": "0bc05f62-f910-4bce-f18c-f7d13e6c357b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
       "                 max_features=1.0, max_samples=1.0, n_estimators=10,\n",
       "                 n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                 warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\r\n",
    "\r\n",
    "bag_regressor = BaggingRegressor(random_state=1)\r\n",
    "bag_regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCAuotaHJCnK",
    "outputId": "d2a269b6-3c37-4e6f-aba3-14411c8b3992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Coefficient of R^2 : 0.980\n",
      "Test Coefficient of R^2 : 0.812\n"
     ]
    }
   ],
   "source": [
    "Y_preds = bag_regressor.predict(X_test)\r\n",
    "\r\n",
    "print('Training Coefficient of R^2 : %.3f'%bag_regressor.score(X_train, Y_train))\r\n",
    "print('Test Coefficient of R^2 : %.3f'%bag_regressor.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG9zkJQ7JGeA",
    "outputId": "865cea05-62d4-4c18-e1a7-5d2c9064836d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 432 out of 432 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2 Score : 0.983\n",
      "Test R^2 Score : 0.802\n",
      "Best R^2 Score Through Grid Search : 0.870\n",
      "Best Parameters :  {'base_estimator': None, 'bootstrap': True, 'bootstrap_features': False, 'max_features': 1.0, 'max_samples': 1.0, 'n_estimators': 50}\n",
      "CPU times: user 1.23 s, sys: 85 ms, total: 1.32 s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "\r\n",
    "n_samples = boston.data.shape[0]\r\n",
    "n_features = boston.data.shape[1]\r\n",
    "\r\n",
    "params = {'base_estimator': [None, LinearRegression(), KNeighborsRegressor()],\r\n",
    "          'n_estimators': [20,50,100],\r\n",
    "          'max_samples': [0.5,1.0],\r\n",
    "          'max_features': [0.5,1.0],\r\n",
    "          'bootstrap': [True, False],\r\n",
    "          'bootstrap_features': [True, False]}\r\n",
    "\r\n",
    "bagging_regressor_grid = GridSearchCV(BaggingRegressor(random_state=1, n_jobs=-1), param_grid =params, cv=3, n_jobs=-1, verbose=1)\r\n",
    "bagging_regressor_grid.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print('Train R^2 Score : %.3f'%bagging_regressor_grid.best_estimator_.score(X_train, Y_train))\r\n",
    "print('Test R^2 Score : %.3f'%bagging_regressor_grid.best_estimator_.score(X_test, Y_test))\r\n",
    "print('Best R^2 Score Through Grid Search : %.3f'%bagging_regressor_grid.best_score_)\r\n",
    "print('Best Parameters : ',bagging_regressor_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm70vQMNJn4J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bagging-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
